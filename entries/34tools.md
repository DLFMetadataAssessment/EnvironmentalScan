---
sectionclass: h2
sectionid: index-tools
parent-id: index
is-parent: yes
number: 34
title: Tools
layout: page
---

   {::options parse_block_html="true" /}

# Tools   
   
<h3>Summary</h3>

In 2016, DLF Metadata Assessment Working Group surveyed and analyzed:
   - general data tools,
   - cultural heritage institution metadata-specific tools,
   - programming languages/libraries that support metadata-specific activities, and
   - datasets and dataset aggregators.

This environmental scan captured information about the use, status, and application of 20 tools. In 2017, the initial list of tools gathered as part of the environmental scan was reviewed with an eye to developing resources for tool testing.

Testing metadata assessment tools is slated to begin late 2017. Subsequent steps include the development of a repository for metadata assessment tools. The repository would include information gathered from the environmental scan as well as data and resources related to the evaluation of metadata asssessment tools.


<h4>How to Read Our Tools Document</h4>

The [Tools Documentation](https://docs.google.com/spreadsheets/d/1PCi_3pcWSFQ9fR54AxwO7LWuBUu2vbVw1etvw_UAl5g/edit?usp=sharing), developed in 2016, is intended to aid the evaluation of tools for potential use in metadata assessment. 

The documentation presents general information about each tool, such as its purpose and type along with a descriptive summary and URL. The documentation also provides details that may influence adoption, such as technical requirements, support, and budgetary considerations. Links to source code and documentation are included for further research. 

<h5>Tools Overview Sheet</h5>

| **Columns** | **Definitions** | **Values** |
| ----------- | --------------- | ---------- |
| Lit Review ID | Identifier to track Tool description across multiple tabs |MA-### (abbreviation for Metadata Assessment with incrementing number) |
| Assessment Grouping | Description of emerging trends identified in the group's literature review which tool supports/could support | Free text |
| Tool Name | Name of the tool assessed |Free text |
| Designed For | Description of intended use based on documentation or user feedback | efficiency and assessment across large datasets, assessing metadata, statistical computing, graphics, integrated development environment (IDE), data visualization, business intelligence, sharing and testing [datasets] |
| Type | Type of tool assessed | programming language or library, stand-alone script, tool, tools package, dataset, computing framework |
| URL | General URL for tool or tool information | URL |
| Abstract | Brief summary of the tool, its significant characteristics and relevant considerations | Free text |
| Other | Additional notes field. |Free text |
| Tool Creator/Maintainer | Individual or organization responsible for tool creation and/or maintenance | Free text |
| Source code / download URL | Destination for source code or download | URL |
| Documentation | Destination for tool documentation | URL |
| GUI | Designates if tool has a graphical user interface | y,n |
| CLI | Designates if tool is available for the command line | y,n |
| Free? | Designates if tool is freely available | y,n |
| OSS or proprietary | Designates if tool is open source or proprietary | OSS, proprietary |
| Written in... | Programming language tool is written in | Free text |


<h3>List of Tools &amp; Sample Datasets to be Assessed</h3>

   - Anaconda distribution of Python
   - Apache Spark
   - Completeness Rating in Europeana
   - D3
   - Digital Public Library of America: Bulk Metadata Download Feb 2015
   - Google Analytics
   - Hadoop
   - Internet Archive Dataset Collection
   - LODrefine
   - Mark Phillips' Metadata Breakers
   - North Carolina Digital Heritage Center DPLA Aggregation tools
   - OpenRefine
   - Plot.ly
   - Python pandas
   - R
   - R Studio
   - SPSS
   - Tableau
   - UNT Libraries Metadata Edit Dataset

<h3>Tools Overview Visualization</h3>

The following charts are snapshots from August 2016. The first chart provides a quick overview of the types of tools selected for review. Many are standalone tools or programming languages; others are tools packages, standalone scripts, or computing frameworks.

<img src="/img/toolsselected.png"/>

The tools we reviewed also reflect the variety of work associated with metadata assessment. Many are designed to help with assessment across large datasets, while others reflect the work of sharing and testing, statistical computing, or data visualization.

<img src="/img/toolsdesigned.png"/>
